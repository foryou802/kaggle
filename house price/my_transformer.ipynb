{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmsle(actual_values, predicted_values):\n",
    "    # 넘파이로 배열 형태로 바꿔준다.\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    actual_values = np.array(actual_values)\n",
    "    \n",
    "    # 예측값과 실제 값에 1을 더하고 로그를 씌워준다.\n",
    "    log_predict = np.log(predicted_values + 1)\n",
    "    log_actual = np.log(actual_values + 1)\n",
    "    \n",
    "    # 위에서 계산한 예측값에서 실제값을 빼주고 제곱을 해준다.\n",
    "    difference = log_predict - log_actual\n",
    "    # difference = (log_predict - log_actual) ** 2\n",
    "    difference = np.square(difference)\n",
    "    \n",
    "    # 평균을 낸다.\n",
    "    mean_difference = difference.mean()\n",
    "    \n",
    "    # 다시 루트를 씌운다.\n",
    "    score = np.sqrt(mean_difference)\n",
    "    \n",
    "    return score\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def neg_rmsle(actual_values, predicted_values):\n",
    "    # 넘파이로 배열 형태로 바꿔준다.\n",
    "    predicted_values = np.array(predicted_values)\n",
    "    actual_values = np.array(actual_values)\n",
    "    \n",
    "    # 예측값과 실제 값에 1을 더하고 로그를 씌워준다.\n",
    "    log_predict = np.log(predicted_values + 1)\n",
    "    log_actual = np.log(actual_values + 1)\n",
    "    \n",
    "    # 위에서 계산한 예측값에서 실제값을 빼주고 제곱을 해준다.\n",
    "    difference = log_predict - log_actual\n",
    "    # difference = (log_predict - log_actual) ** 2\n",
    "    difference = np.square(difference)\n",
    "    \n",
    "    # 평균을 낸다.\n",
    "    mean_difference = difference.mean()\n",
    "    \n",
    "    # 다시 루트를 씌운다.\n",
    "    score = np.sqrt(mean_difference) * (-1)\n",
    "    \n",
    "    return score\n",
    "\n",
    "neg_rmsle_scorer = make_scorer(neg_rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class change_to_datetime(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name=None):\n",
    "        self.column_name = column_name\n",
    "        \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        df_X[self.column_name] = pd.to_datetime(df_X[self.column_name])\n",
    "        return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class change_to_str(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name=None):\n",
    "        self.column_name = column_name\n",
    "        \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        df_X[self.column_name] = df_X[self.column_name].astype('str')\n",
    "        return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class divide_datetime(BaseEstimator, TransformerMixin):       \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        df_X[\"year\"] = df_X[\"datetime\"].dt.year\n",
    "        df_X[\"month\"] = df_X[\"datetime\"].dt.month\n",
    "        df_X[\"day\"] = df_X[\"datetime\"].dt.day\n",
    "        df_X[\"hour\"] = df_X[\"datetime\"].dt.hour\n",
    "        return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_dayofweek(BaseEstimator, TransformerMixin):       \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        df_X[\"dayofweek\"] = df_X[\"datetime\"].dt.dayofweek\n",
    "        return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_columns(df_X) :\n",
    "    columns = list(df_X.columns)\n",
    "\n",
    "    num_columns = []\n",
    "    cat_columns = []\n",
    "\n",
    "    for column in columns :\n",
    "        if df_X[column].dtypes == 'object' :\n",
    "            cat_columns.append(column)\n",
    "\n",
    "        else :\n",
    "            num_columns.append(column)\n",
    "\n",
    "    return num_columns, cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_selection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        return df_X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_hot_encoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name=None, prefix=None):\n",
    "        self.column_name = column_name\n",
    "        self.prefix = prefix\n",
    "        \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        onehotencoding = pd.get_dummies(df_X[self.column_name], prefix = self.prefix)\n",
    "        df_X.drop(self.column_name, axis=1, inplace=True)\n",
    "        return pd.concat([df_X, onehotencoding], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class standard_scaler(BaseEstimator, TransformerMixin):      \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X, y=None):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df_X)\n",
    "        X = scaler.transform(df_X)\n",
    "        df_X = pd.DataFrame(X, columns=df_X.columns, index=df_X.index)\n",
    "        return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_imputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='mean'):\n",
    "        self.strategy = strategy\n",
    "        \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        imputer = SimpleImputer(strategy=self.strategy)\n",
    "        np_X = imputer.fit_transform(df_X)\n",
    "        df_X = pd.DataFrame(np_X, columns=df_X.columns, index=df_X.index)\n",
    "        \n",
    "        return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_columns(df, columns, strategy='constant', value=0) :\n",
    "    \n",
    "    if strategy == 'constant' :\n",
    "        df[columns].fillna(value, inplace=True)\n",
    "        \n",
    "    elif strategy == 'mean' :\n",
    "        value = df[columns].mean()\n",
    "        df[columns].fillna(value, inplace=True)\n",
    "        \n",
    "    elif strategy == 'median' :\n",
    "        value = df[columns].median()\n",
    "        df[columns].fillna(value, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_imputer(df, column_imp, columns_rf) :\n",
    "    \n",
    "    df_impute = df[df[column_imp].isnull()]\n",
    "    df_rf = df[df[column_imp].notnull()]\n",
    "    \n",
    "#     df_rf[column_imp] = df_rf[column_imp].astype('str')\n",
    "    \n",
    "    rf_imp = RandomForestClassifier()\n",
    "    rf_imp.fit(df_rf[columns_rf], df_rf[column_imp])\n",
    "    impute_values = rf_imp.predict(df_impute[columns_rf])\n",
    "    df_impute[column_imp] = impute_values\n",
    "    \n",
    "    df_new = pd.concat([df_impute, df_rf], axis=0)\n",
    "    \n",
    "#     df_new[column_imp] = df_new[column_imp].astype('float')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(df_A, df_B) : \n",
    "    return pd.concat([df_A, df_B], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_list(df_list) : \n",
    "    return pd.concat(df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class drop_feature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, df_X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_X):\n",
    "        df_X.drop(self.columns, axis=1, inplace=True)\n",
    "        return df_X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
