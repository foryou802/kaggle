{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.externals import joblib   # 함수는 dump 시켜도 안됨\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, f_regression, SelectFromModel, RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_transformer import change_to_str, divide_columns, feature_selection, simple_imputer, one_hot_encoding, concat, rf_imputer, fill_columns\n",
    "from my_transformer import rmsle_scorer, neg_rmsle_scorer, rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(data) :\n",
    "    \n",
    "    data.drop(['SalePrice', 'Id'], axis=1, inplace=True)\n",
    "    \n",
    "    astype_str = change_to_str('MSSubClass')\n",
    "    data = astype_str.fit_transform(data)\n",
    "          \n",
    "    data.drop(['Alley', 'Fence', 'FireplaceQu', 'MiscFeature', 'PoolQC'], axis=1, inplace=True)\n",
    "    \n",
    "    num_columns, cat_columns = divide_columns(data)\n",
    "    \n",
    "    pipeline_cat = make_pipeline(\n",
    "        feature_selection(cat_columns),\n",
    "#         simple_imputer('most_frequent'),\n",
    "        one_hot_encoding(cat_columns)\n",
    "    )\n",
    "    \n",
    "    X_cat = pipeline_cat.fit_transform(data)\n",
    "    X_num = data[num_columns]\n",
    "    X = concat(X_num, X_cat)\n",
    "    \n",
    "    isnull_sum = X.isnull().sum()\n",
    "    not_null = list(isnull_sum[isnull_sum == 0].index)\n",
    "    null_columns = list(isnull_sum[isnull_sum > 0])\n",
    "    \n",
    "    for column in num_columns :\n",
    "        X = fill_columns(X, column, 'mean')\n",
    "        \n",
    "    isnull_sum = X.isnull().sum()\n",
    "    print(isnull_sum[isnull_sum > 0].sort_values(ascending=False))\n",
    "    \n",
    "    skew_features = X[num_columns].apply(lambda x : skew(x))\n",
    "    skew_features_top = skew_features[skew_features > 1]\n",
    "    X[skew_features_top.index] = np.log1p(X[skew_features_top.index])\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set() :\n",
    "    train = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    \n",
    "    data = pd.concat([train, test], axis=0)\n",
    "    \n",
    "    X = preparation(data)\n",
    "    X_train = X.iloc[:1460, :]\n",
    "    X_test = X.iloc[1460:, :]\n",
    "    \n",
    "    y = train['SalePrice']\n",
    "    y_train = np.log1p(y)\n",
    "    \n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(column) :\n",
    "    index_outlier = X_train[abs(X_train[column] - X_train[column].mean()) > (3 * X_train[column].std())].index\n",
    "    print(len(index_outlier))\n",
    "    X_train.drop(index=index_outlier, axis=0, inplace=True)\n",
    "    y_train.drop(index=index_outlier, axis=0, inplace=True)\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train = data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(1452, 285)\n"
     ]
    }
   ],
   "source": [
    "remove_outlier('GrLivArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10, random_state=30)\n",
    "lasso = Lasso(alpha=0.001, random_state=30)\n",
    "elastic = ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=30)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=30)\n",
    "xgb = XGBRegressor(random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ridge' : ridge,\n",
    "    'lasso' : lasso,\n",
    "    'elastic' : elastic\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge': 0.113, 'lasso': 0.112, 'elastic': 0.11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dict()\n",
    "\n",
    "for key, model in models.items() : \n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()   \n",
    "    scores[key] = round(np.sqrt(-score), 3)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in models.items() :\n",
    "    score = scores[key]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    prediction = np.exp(prediction)\n",
    "    \n",
    "    submission = pd.read_csv(\"sample_submission.csv\")\n",
    "    submission[\"SalePrice\"] = prediction\n",
    "    submission.to_csv(\"score_{}_{:.3f}_submission.csv\".format(key, score), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, random_state=30)\n",
    "\n",
    "ridge.fit(X_train_split, y_train_split)\n",
    "lasso.fit(X_train_split, y_train_split)\n",
    "elastic.fit(X_train_split, y_train_split)\n",
    "\n",
    "y_rideg = ridge.predict(X_test_split)\n",
    "y_lasso = lasso.predict(X_test_split)\n",
    "y_elestic = elastic.predict(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = {\n",
    "    'r_4_l_6' : 0.4 * y_rideg + 0.6 * y_lasso,\n",
    "    'l_4_e_6' : 0.4 * y_lasso + 0.6 * y_elestic,\n",
    "    'l_6_e_4' : 0.6 * y_lasso + 0.4 * y_elestic,\n",
    "    'l_8_e_2' : 0.8 * y_lasso + 0.2 * y_elestic,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "def rmse(dic) :\n",
    "    for key, value in dic.items() :\n",
    "        mse = mean_squared_error(y_test_split, value)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        scores[key] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r_4_l_6': 0.11766882639179346,\n",
       " 'l_4_e_6': 0.11746850322207804,\n",
       " 'l_6_e_4': 0.11739662085858443,\n",
       " 'l_8_e_2': 0.11744174909977348}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(predict)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "y_rideg = ridge.predict(X_test)\n",
    "y_lasso = lasso.predict(X_test)\n",
    "y_elestic = elastic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = {\n",
    "    'r_4_l_6' : 0.4 * y_rideg + 0.6 * y_lasso,\n",
    "    'l_4_e_6' : 0.4 * y_lasso + 0.6 * y_elestic,\n",
    "    'l_6_e_4' : 0.6 * y_lasso + 0.4 * y_elestic,\n",
    "    'l_8_e_2' : 0.8 * y_lasso + 0.2 * y_elestic,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, pred in predict.items() :\n",
    "    score = scores[key]\n",
    "\n",
    "    prediction = np.exp(pred)\n",
    "    \n",
    "    submission = pd.read_csv(\"sample_submission.csv\")\n",
    "    submission[\"SalePrice\"] = prediction\n",
    "    submission.to_csv(\"score_{}_{:.3f}_submission.csv\".format(key, score), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "ElasticNet  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "GradientBoostingRegressor  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "XGBRegressor  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "[20:36:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  1  시작 \n",
      "[20:36:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  2  시작 \n",
      "[20:36:10] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  3  시작 \n",
      "[20:36:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  4  시작 \n",
      "[20:36:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# get_stacking_base_datasets( )은 넘파이 ndarray를 인자로 사용하므로 DataFrame을 넘파이로 변환. \n",
    "X_train_n = X_train_split.values\n",
    "X_test_n = X_test_split.values\n",
    "y_train_n = y_train_split.values\n",
    "\n",
    "# 각 개별 기반(Base)모델이 생성한 학습용/테스트용 데이터 반환. \n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge, X_train_n, y_train_n, X_test_n, 5)\n",
    "elastic_train, elastic_test = get_stacking_base_datasets(elastic, X_train_n, y_train_n, X_test_n, 5)\n",
    "gb_train, gb_test = get_stacking_base_datasets(gb, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb, X_train_n, y_train_n, X_test_n, 5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스태킹 회귀 모델의 최종 RMSE 값은: 0.116\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델이 반환한 학습 및 테스트용 데이터 세트를 Stacking 형태로 결합.  \n",
    "Stack_final_X_train = np.concatenate((ridge_train, elastic_train, gb_train, xgb_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((ridge_test, elastic_test, gb_test, xgb_test), axis=1)\n",
    "\n",
    "# 최종 메타 모델은 라쏘 모델을 적용. \n",
    "meta_model_lasso = Lasso(alpha=0.001, random_state=30)\n",
    "\n",
    "#기반 모델의 예측값을 기반으로 새롭게 만들어진 학습 및 테스트용 데이터로 예측하고 RMSE 측정.\n",
    "meta_model_lasso.fit(Stack_final_X_train, y_train_split)\n",
    "final = meta_model_lasso.predict(Stack_final_X_test)\n",
    "mse = mean_squared_error(y_test_split , final)\n",
    "rmse = np.sqrt(mse)\n",
    "print('스태킹 회귀 모델의 최종 RMSE 값은:', round(rmse, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(rmse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "ElasticNet  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "GradientBoostingRegressor  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "XGBRegressor  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "[20:36:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  1  시작 \n",
      "[20:36:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  2  시작 \n",
      "[20:36:31] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  3  시작 \n",
      "[20:36:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\t 폴드 세트:  4  시작 \n",
      "[20:36:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# get_stacking_base_datasets( )은 넘파이 ndarray를 인자로 사용하므로 DataFrame을 넘파이로 변환. \n",
    "X_train_n = X_train.values\n",
    "X_test_n = X_test.values\n",
    "y_train_n = y_train.values\n",
    "\n",
    "# 각 개별 기반(Base)모델이 생성한 학습용/테스트용 데이터 반환. \n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge, X_train_n, y_train_n, X_test_n, 5)\n",
    "elastic_train, elastic_test = get_stacking_base_datasets(elastic, X_train_n, y_train_n, X_test_n, 5)\n",
    "gb_train, gb_test = get_stacking_base_datasets(gb, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb, X_train_n, y_train_n, X_test_n, 5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델이 반환한 학습 및 테스트용 데이터 세트를 Stacking 형태로 결합.  \n",
    "Stack_final_X_train = np.concatenate((ridge_train, elastic_train, gb_train, xgb_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((ridge_test, elastic_test, gb_test, xgb_test), axis=1)\n",
    "\n",
    "# 최종 메타 모델은 라쏘 모델을 적용. \n",
    "meta_model_lasso = Lasso(alpha=0.001, random_state=30)\n",
    "\n",
    "#기반 모델의 예측값을 기반으로 새롭게 만들어진 학습 및 테스트용 데이터로 예측하고 RMSE 측정.\n",
    "meta_model_lasso.fit(Stack_final_X_train, y_train)\n",
    "prediction = meta_model_lasso.predict(Stack_final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.exp(pred)\n",
    "    \n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission[\"SalePrice\"] = prediction\n",
    "submission.to_csv(\"score_{}_{:.3f}_submission.csv\".format('stack', score), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
